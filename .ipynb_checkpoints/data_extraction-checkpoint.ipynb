{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5426c9-fd49-46a6-bc59-c80ce4348d60",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd00dc23-645c-4cd1-9309-d8eb0deb1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aadefb7-f8c3-4cde-96b7-89246fe05189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapefiles(root_dir='.'):\n",
    "    \"\"\"\n",
    "    Recursively finds all .shp files in a directory and its subdirectories.\n",
    "    \n",
    "    Args:\n",
    "        root_dir (str): The path to the starting directory.\n",
    "        \n",
    "    Returns:\n",
    "        dictionary: A dictionary where:\n",
    "            - Key = filename without extension (string, e.g., 'my_map')\n",
    "            - Value = Full Path object (Path, e.g., 'C:/Data/2022/my_map.shp')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Iterate over all .shp files\n",
    "    return { path.stem : path for path in Path(root_dir).rglob('*.shp')}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0813289d-0cac-49e2-ad6d-1c0fda0ac941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excel(shapefiles, output_folder='data_miteco_excel'):\n",
    "    \"\"\"\n",
    "    Converts a dictionary of Shapefile paths into Excel files, dropping geometric data.\n",
    "\n",
    "    Args:\n",
    "        shapefiles (dict): A dictionary where keys are filenames (str) and \n",
    "                           values are file paths (Path or str).\n",
    "        output_folder (str, optional): The directory where Excel files will be saved. \n",
    "                                       Defaults to 'data_miteco_excel'.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return a value; it saves files to disk.\n",
    "    \"\"\"\n",
    "\n",
    "    folder = Path(output_folder)\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for name, path in shapefiles.items():\n",
    "        try:\n",
    "            # Load shapefile\n",
    "            gdf = gpd.read_file(path)\n",
    "    \n",
    "            # Drop geometry (keep only tabular data)\n",
    "            table = gdf.drop(columns='geometry', errors='ignore')\n",
    "    \n",
    "            # Save to Excel\n",
    "            excel_path = folder / (name + '.xlsx')\n",
    "            \n",
    "            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "                table.to_excel(writer, index=False)\n",
    "                \n",
    "            print(f\"Successfully saved: {excel_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4755d86e-bc38-4372-87d2-245635906fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(shapefiles, join_key='natcode'):\n",
    "    master_gdf = None\n",
    "\n",
    "    for name, path in shapefiles.items():\n",
    "        # 1. Read file\n",
    "        current_gdf = gpd.read_file(path)\n",
    "        \n",
    "        # 2. Check for the key\n",
    "        if join_key not in current_gdf.columns:\n",
    "            continue\n",
    "\n",
    "        if master_gdf is None:\n",
    "            # First file sets the standard\n",
    "            master_gdf = current_gdf\n",
    "        else:\n",
    "            # 3. INTELLIGENT COLUMN SELECTION\n",
    "            # We only keep columns that are NOT already in the master_gdf\n",
    "            # (But we MUST keep the join_key to perform the merge)\n",
    "            cols_to_use = [join_key] # Start with the key\n",
    "            \n",
    "            for col in current_gdf.columns:\n",
    "                if col != join_key and col not in master_gdf.columns:\n",
    "                     cols_to_use.append(col)\n",
    "            \n",
    "            # 4. Prepare the slice to merge\n",
    "            # We only take the new columns + the key\n",
    "            data_to_merge = pd.DataFrame(current_gdf)[cols_to_use]\n",
    "            \n",
    "            # 5. Merge\n",
    "            master_gdf = master_gdf.merge(\n",
    "                data_to_merge, \n",
    "                on=join_key, \n",
    "                how='outer'\n",
    "            )\n",
    "            \n",
    "    return master_gdf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e4eb7a-bf6b-4ac4-a8b4-8cc0211f5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved: data_miteco_excel\\PctAutoc_2022.xlsx\n",
      "Successfully saved: data_miteco_excel\\CifraPob2023.xlsx\n",
      "Successfully saved: data_miteco_excel\\DensPob2023.xlsx\n",
      "Successfully saved: data_miteco_excel\\EdadMedia2023.xlsx\n",
      "Successfully saved: data_miteco_excel\\NumAfi_2022.xlsx\n",
      "Successfully saved: data_miteco_excel\\NumParados_2022.xlsx\n",
      "Successfully saved: data_miteco_excel\\PctPob65_2022.xlsx\n",
      "Successfully saved: data_miteco_excel\\PctPob16_2021.xlsx\n",
      "Successfully saved: data_miteco_excel\\PctPobExt_2022.xlsx\n",
      "Successfully saved: data_miteco_excel\\RatioMasc_2023.xlsx\n",
      "Successfully saved: data_miteco_excel\\RentaMedia_2020.xlsx\n",
      "Successfully saved: data_miteco_excel\\VarPob2014_2023.xlsx\n"
     ]
    }
   ],
   "source": [
    "shapefiles = get_shapefiles()\n",
    "create_excel(shapefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beadb7be-d183-47b2-941e-0ad16cd5be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = extract_data(shapefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd8d6a2-a92e-43e6-88dd-8cfc127701a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataLayerError",
     "evalue": "Failed to create file data_miteco_shape\\data_miteco.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCPLE_AppDefinedError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:2480\u001b[39m, in \u001b[36mpyogrio._io.create_ogr_dataset_layer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_err.pyx:218\u001b[39m, in \u001b[36mpyogrio._err.check_pointer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCPLE_AppDefinedError\u001b[39m: Failed to create file data_miteco_shape\\data_miteco.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mDataLayerError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata_miteco_shape/data_miteco.shp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mESRI Shapefile\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\tfgInfo\\Lib\\site-packages\\geopandas\\geodataframe.py:1632\u001b[39m, in \u001b[36mGeoDataFrame.to_file\u001b[39m\u001b[34m(self, filename, driver, schema, index, **kwargs)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[32m   1539\u001b[39m \n\u001b[32m   1540\u001b[39m \u001b[33;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1628\u001b[39m \n\u001b[32m   1629\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1630\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[32m-> \u001b[39m\u001b[32m1632\u001b[39m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\tfgInfo\\Lib\\site-packages\\geopandas\\io\\file.py:731\u001b[39m, in \u001b[36m_to_file\u001b[39m\u001b[34m(df, filename, driver, schema, index, mode, crs, engine, metadata, **kwargs)\u001b[39m\n\u001b[32m    728\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m should be one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, got \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyogrio\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m     \u001b[43m_to_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mfiona\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    733\u001b[39m     _to_file_fiona(df, filename, driver, schema, crs, mode, metadata, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\tfgInfo\\Lib\\site-packages\\geopandas\\io\\file.py:793\u001b[39m, in \u001b[36m_to_file_pyogrio\u001b[39m\u001b[34m(df, filename, driver, schema, crs, mode, metadata, **kwargs)\u001b[39m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df.columns.is_unique:\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mGeoDataFrame cannot contain duplicated column names.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m \u001b[43mpyogrio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\tfgInfo\\Lib\\site-packages\\pyogrio\\geopandas.py:917\u001b[39m, in \u001b[36mwrite_dataframe\u001b[39m\u001b[34m(df, path, layer, driver, encoding, geometry_type, promote_to_multi, nan_as_null, append, use_arrow, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, **kwargs)\u001b[39m\n\u001b[32m    914\u001b[39m         field_data.append(values)\n\u001b[32m    915\u001b[39m         field_mask.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\tfgInfo\\Lib\\site-packages\\pyogrio\\raw.py:733\u001b[39m, in \u001b[36mwrite\u001b[39m\u001b[34m(path, geometry, field_data, fields, field_mask, layer, driver, geometry_type, crs, encoding, promote_to_multi, nan_as_null, append, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, gdal_tz_offsets, **kwargs)\u001b[39m\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# preprocess kwargs and split in dataset and layer creation options\u001b[39;00m\n\u001b[32m    729\u001b[39m dataset_kwargs, layer_kwargs = _preprocess_options_kwargs(\n\u001b[32m    730\u001b[39m     driver, dataset_options, layer_options, kwargs\n\u001b[32m    731\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m \u001b[43mogr_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:2599\u001b[39m, in \u001b[36mpyogrio._io.ogr_write\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:2496\u001b[39m, in \u001b[36mpyogrio._io.create_ogr_dataset_layer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mDataLayerError\u001b[39m: Failed to create file data_miteco_shape\\data_miteco.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "    folder = Path(output_folder)\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "gdf.to_file(\"data_miteco_shape/data_miteco.shp\", driver='ESRI Shapefile', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350528b1-73e4-4688-9e3f-aa7bad0c650e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
